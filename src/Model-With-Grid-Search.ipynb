{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from champion_net import ChampionNet\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#config\n",
        "config = {\n",
        "    'data_set': '../../data/filtered-dataset-no-header.csv',\n",
        "    'model': {\n",
        "        'save': False,\n",
        "        'save_location': '../models',\n",
        "        'layer_size': [32, 64, 128, 256],\n",
        "        'dropout_rate': [0.5],\n",
        "        'learning_rate': [0.0005, 0.005, 0.01]\n",
        "    },\n",
        "    'batch_size': 50000,\n",
        "    'epochs': [10,15,20],\n",
        "    'validation_set_size': 0.1,\n",
        "    'test_set_size': 0.1,\n",
        "    'lambda1': 0.5,\n",
        "    'lambda2' : 0.01,\n",
        "    'show_graphs': False,\n",
        "    'graph_locations': '../graphs',\n",
        "    'device': 'cpu'\n",
        "}\n",
        "\n",
        "device = torch.device(config['device'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#training the nn functions\n",
        "def accuracy(outputs, y):\n",
        "    matches = [torch.argmax(i, 0) == torch.argmax(j,0) for i,j in zip(outputs,y)]\n",
        "    return matches.count(True)/len(matches)\n",
        "    \n",
        "def forward_pass(net, X,y,train = False):\n",
        "    if train:\n",
        "        optimizer.zero_grad()\n",
        "    outputs = net(X)\n",
        "    acc = accuracy(outputs, y)\n",
        "    cross_entropy_loss = loss_function(outputs,y)\n",
        "\n",
        "    all_linear2_params = torch.cat([x.view(-1) for x in net.fc2.parameters()])\n",
        "    l2_regularization = lambda2 * torch.norm(all_linear2_params, 2)\n",
        "\n",
        "    loss = cross_entropy_loss + l2_regularization\n",
        "\n",
        "    if train:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return acc, loss\n",
        "\n",
        "def test(net, val_X, val_y, size=32):\n",
        "    X, y = val_X[:size], val_y[:size]\n",
        "    val_acc, val_loss = forward_pass(net, X.view(-1,154).to(device), y.to(device).view(-1,2))\n",
        "    return val_acc, val_loss\n",
        "\n",
        "def train(net, train_X, train_y,model_name, epochs):\n",
        "    log = {\n",
        "        'times': [],\n",
        "        'acc': [],\n",
        "        'loss': [],\n",
        "        'val_acc': [],\n",
        "        'val_loss': [],\n",
        "    }\n",
        "    for epoch in range(epochs):\n",
        "        for i in tqdm(range(0, len(train_X), config['batch_size'])): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:100] ..for now just to dev\n",
        "            batch_X = train_X[i:i+config['batch_size']].view(-1,154)\n",
        "            batch_y = train_y[i:i+config['batch_size']].view(-1, 2)\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            \n",
        "            acc, loss = forward_pass(net, batch_X, batch_y, train=True)\n",
        "        \n",
        "            if i % config['batch_size'] == 0:\n",
        "                val_acc, val_loss = test(net, val_X, val_y, size=config['batch_size'])\n",
        "                log['times'].append(time.time())\n",
        "                log['acc'].append(round(float(acc),2))\n",
        "                log['loss'].append(round(float(loss), 4))\n",
        "                log['val_acc'].append(round(float(val_acc),2))\n",
        "                log['val_loss'].append(round(float(val_loss),4))\n",
        "    return log\n",
        "\n",
        "def create_acc_loss_graph(training_results, model_name, save_graphs, show_graphs):\n",
        "    times = [time - training_results['times'][0] for time in training_results['times']]\n",
        "    data = [training_results['acc'],training_results['loss'],training_results['val_acc'],training_results['val_loss']]\n",
        "    y_labels = ['accuracy', 'loss', 'validation_accuracy', 'validation_loss']\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        create_and_save_graph(times, data[i], 'iterations', y_labels[i], model_name, save_graphs, show_graphs)\n",
        "\n",
        "def create_and_save_graph(x, y, x_label, y_label, model_name, save_graph, show_graph):\n",
        "    plt.plot(x, y)\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(y_label)\n",
        "    if save_graph:\n",
        "         plt.savefig(f\"{config['model']['save_location']}/{model_name}/{y_label}.png\", format='png', bbox_inches='tight')\n",
        "    if show_graph:\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#useful helper functions\n",
        "def convert_to_state(combination):\n",
        "    res = [0 for i in range(154)] #154 champions\n",
        "    for i in range(5):\n",
        "        res[int(combination[i])] = 1\n",
        "    \n",
        "    for i in range(5, 10):\n",
        "        res[int(combination[i])] = -1\n",
        "    return res\n",
        "\n",
        "\n",
        "def create_features_and_labels(dataset):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for point in dataset:\n",
        "        feature_state = convert_to_state([int(x) for x in point[0][:10]])\n",
        "        features.append(feature_state)\n",
        "        blue_victory = int(point[0][10]) #1 if blue victory, 0 otherwise\n",
        "        labels.append([blue_victory, 1 - blue_victory])\n",
        "    \n",
        "    return torch.Tensor(features), torch.Tensor(labels)\n",
        "\n",
        "def load_data_set(filename, validation_set_size,test_set_size, delimiter=','):\n",
        "    dataset = []\n",
        "    with open(filename, 'r') as f:\n",
        "        reader = csv.reader(f, delimiter=delimiter)\n",
        "        for row in reader:\n",
        "            dataset.append(np.array([row]))\n",
        "\n",
        "\n",
        "    print(f'The size of the entire dataset is {len(dataset)} points')\n",
        "    val_size = int(len(dataset) * validation_set_size)\n",
        "    test_size = int(len(dataset) * test_set_size)\n",
        "    train_size = len(dataset) - val_size - test_size\n",
        "    random.shuffle(dataset)\n",
        "\n",
        "    train_set = dataset[:train_size]\n",
        "    val_set = dataset[train_size:(val_size + train_size)]\n",
        "    test_set = dataset[(val_size + train_size):(val_size + train_size+test_size)]\n",
        "\n",
        "    return train_set, val_set, test_set\n",
        "\n",
        "def save_trained_network(net, net_name, location):\n",
        "    os.mkdir(f'{location}/{net_name}')\n",
        "    path = f'{location}/{net_name}/model.pickle'\n",
        "    torch.save(net.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the entire dataset is 966973 points\n"
          ]
        }
      ],
      "source": [
        "    \n",
        "#Generate the validation and training sets\n",
        "training_set, validation_set, test_set = load_data_set(config['data_set'], config['validation_set_size'], config['test_set_size'])\n",
        "\n",
        "train_X, train_y = create_features_and_labels(training_set)\n",
        "val_X, val_y = create_features_and_labels(validation_set)\n",
        "test_X, test_y = create_features_and_labels(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = {\n",
        "    \"layer_size\": 0,\n",
        "    \"epochs\": 0, \n",
        "    \"learning_rate\": 0 ,\n",
        "}\n",
        "\n",
        "best_test_acc = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.59s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.60s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.61s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.62s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.60s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.62s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.60s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.61s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.65s/it]\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]Test accuracy of model with hyperparameters: 32, 10, 0.0005: 0.5357870461337993\n",
            "100%|██████████| 16/16 [00:43<00:00,  2.70s/it]\n",
            "100%|██████████| 16/16 [00:44<00:00,  2.78s/it]\n",
            "100%|██████████| 16/16 [00:43<00:00,  2.71s/it]\n",
            "100%|██████████| 16/16 [00:44<00:00,  2.78s/it]\n",
            "100%|██████████| 16/16 [00:47<00:00,  2.94s/it]\n",
            "100%|██████████| 16/16 [00:43<00:00,  2.70s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.64s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.61s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.62s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.63s/it]\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]Test accuracy of model with hyperparameters: 32, 10, 0.005: 0.5405338324870471\n",
            "100%|██████████| 16/16 [00:43<00:00,  2.74s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.59s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.54s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.54s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.56s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.55s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.56s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.64s/it]\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]Test accuracy of model with hyperparameters: 32, 10, 0.01: 0.5408544215435847\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.54s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.55s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.55s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.55s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.54s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.53s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.54s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.55s/it]\n",
            "100%|██████████| 16/16 [00:40<00:00,  2.53s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.67s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.66s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.67s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.64s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.65s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.64s/it]\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]Test accuracy of model with hyperparameters: 32, 15, 0.0005: 0.5379691200347477\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.61s/it]\n",
            "100%|██████████| 16/16 [00:42<00:00,  2.67s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.59s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.58s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.58s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.58s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.57s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.58s/it]\n",
            "100%|██████████| 16/16 [00:41<00:00,  2.58s/it]\n",
            " 81%|████████▏ | 13/16 [00:36<00:08,  2.79s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-18-bdd2ad37c3b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mloss_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[1;31m#save the model, if configured to do so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-14-e06fd143e272>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, train_X, train_y, model_name, epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-14-e06fd143e272>\u001b[0m in \u001b[0;36mforward_pass\u001b[1;34m(net, X, y, train)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mcross_entropy_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-14-e06fd143e272>\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(outputs, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#training the nn functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-14-e06fd143e272>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#training the nn functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#perform the grid search\n",
        "for layer_size in  config['model']['layer_size']:\n",
        "    for epoch in config['epochs']:\n",
        "        for lr in config['model']['learning_rate']:\n",
        "            for dropout_rate in config['model']['dropout_rate']:\n",
        "                lambda1 = config['lambda1']\n",
        "                lambda2 = config['lambda2'] \n",
        "\n",
        "                model_name = f\"champion-model-{int(time.time())}-{layer_size}-{epoch}-{lr}\"\n",
        "                \n",
        "                net = ChampionNet(num_units=layer_size).to(device)\n",
        "                \n",
        "                optimizer = optim.Adam(net.parameters(),lr = lr)\n",
        "                \n",
        "                loss_function = nn.BCEWithLogitsLoss()\n",
        "                \n",
        "                res = train(net, train_X, train_y,model_name, epoch)\n",
        "\n",
        "                #save the model, if configured to do so\n",
        "                if(config['model']['save']):\n",
        "                    save_trained_network(net, model_name, config['model']['save_location'])\n",
        "\n",
        "                #make the graphs\n",
        "                create_acc_loss_graph(res, model_name, config['model']['save'], config['show_graphs'])\n",
        "\n",
        "                #run on the test set to determine accuracy\n",
        "                test_acc, test_loss = test(net, test_X, test_y, size=len(test_X))\n",
        "                print(f'Test accuracy of model with hyperparameters: {layer_size}, {epoch}, {lr}: {test_acc}')\n",
        "                if test_acc > best_test_acc:\n",
        "                    best_params['layer_size'] = layer_size\n",
        "                    best_params['epochs'] = epoch\n",
        "                    best_params['learning_rate'] = lr\n",
        "                    best_test_acc = test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "cadefb1bbb44194cece66c90f56d73143e5b9dc08cec6be9253223b7ab9c586f"
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}